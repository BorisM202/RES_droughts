{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import atlite\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locations of farms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read capacity of wind and PV farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity_pv = pd.read_csv('../Data_Final/EirGrid/capacity_pv_1724_eir.csv',\n",
    "                               index_col = 2,\n",
    "                               parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity_wind = pd.read_csv('../Data_Final/EirGrid/capacity_wind_9224_eir.csv',\n",
    "                               index_col = 2,\n",
    "                               parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns to be correctly read by Atlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity_pv = df_capacity_pv.dropna().rename(columns={'Capacity (MW)':'capacity', 'Latitude':'y', 'Longitude':'x'})\n",
    "df_capacity_pv = df_capacity_pv[df_capacity_pv.index < '2024'] # Make sure to remove all data before 2024\n",
    "\n",
    "df_capacity_wind = df_capacity_wind.dropna().rename(columns={'Capacity (MW)':'capacity', 'Latitude':'y', 'Longitude':'x'})\n",
    "df_capacity_wind = df_capacity_wind[df_capacity_wind.index < '2024'] # Make sure to remove all data before 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cutout for Ireland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create a time dependent layout of the capacity from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dependent_capacity_distribution(cutout_ie: atlite.Cutout, df_capacity: pd.DataFrame):\n",
    "    capacity_layout = cutout_ie.data['roughness'].copy()\n",
    "    capacity_layout.name = 'Capacity'\n",
    "    capacity_layout[:,:,:] = 0.\n",
    "\n",
    "    #Â Iterate over all capacity installations\n",
    "    for idx, row in tqdm(df_capacity.reset_index().iterrows(), total= df_capacity.shape[0]):\n",
    "        cap = row['capacity'] # Capacity values\n",
    "        df_capacity_i = pd.DataFrame([row])\n",
    "        layout = cutout_ie.layout_from_capacity_list(df_capacity_i, col=\"capacity\")\n",
    "\n",
    "        capacity_layout[capacity_layout['time'] >= row['Connection date']] += layout\n",
    "\n",
    "    return capacity_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/anaconda3/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.24.2\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_uv100_to2018 = xr.open_dataset('../Data/ERA5/ERA5_100m_u_v_hourly_2009_2018.nc')\n",
    "ds_uv100_2019_2023 = xr.open_dataset('../Data/ERA5/ERA5_100m_u_v_hourly_2019_2023.nc')\n",
    "ds_roughness_2018_2023 = xr.open_dataset('../Data/ERA5/ERA5_forecast_surface_roughness_geopotential_hourly_2018_2023.nc')\n",
    "ds_roughness_to2017 = xr.open_dataset('../Data/ERA5/ERA5_forecast_surface_roughness_geopotential_hourly_2012_2017.nc')\n",
    "ds_uv100_to2018 = ds_uv100_to2018.sel(time=slice(\"2014-01-01\", \"2018-12-31\"))\n",
    "ds_roughness_to2018 = ds_roughness_to2017.sel(time=slice(\"2014-01-01\", \"2017-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables need to be formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv100_2019_2023 = ds_uv100_2019_2023.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_roughness_2018_2023 = ds_roughness_2018_2023.reduce(np.nansum, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset does not contain the dimensions: ['expver']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m ds_uv100_2019_2023 \u001b[38;5;241m=\u001b[39m ds_uv100_2019_2023\u001b[38;5;241m.\u001b[39mreduce(np\u001b[38;5;241m.\u001b[39mnansum, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpver\u001b[39m\u001b[38;5;124m'\u001b[39m,keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m      2\u001b[0m ds_roughness_2018_2023 \u001b[38;5;241m=\u001b[39m ds_roughness_2018_2023\u001b[38;5;241m.\u001b[39mreduce(np\u001b[38;5;241m.\u001b[39mnansum, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpver\u001b[39m\u001b[38;5;124m'\u001b[39m,keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/dataset.py:5941\u001b[0m, in \u001b[0;36mDataset.reduce\u001b[0;34m(self, func, dim, keep_attrs, keepdims, numeric_only, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   5939\u001b[0m missing_dimensions \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dims \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims]\n",
      "\u001b[1;32m   5940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dimensions:\n",
      "\u001b[0;32m-> 5941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m   5942\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset does not contain the dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_dimensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   5943\u001b[0m     )\n",
      "\u001b[1;32m   5945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   5946\u001b[0m     keep_attrs \u001b[38;5;241m=\u001b[39m _get_keep_attrs(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset does not contain the dimensions: ['expver']"
     ]
    }
   ],
   "source": [
    "ds_uv100_2019_2023 = ds_uv100_2019_2023.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_roughness_2018_2023 = ds_roughness_2018_2023.reduce(np.nansum, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv100 = xr.concat([ds_uv100_to2018.rename({'lat':'latitude', 'lon':'longitude'}), ds_uv100_2019_2023], dim='time')\n",
    "ds_roughness = xr.concat([ds_roughness_to2017, ds_roughness_2018_2023], dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([ds_uv100, ds_roughness])\n",
    "ds = ds.sel(time=slice(\"2014-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the climate variables in Atlite\n",
    "\n",
    "This can only be done via the function get_cutout_from_era5_data which is not originally in the Atlite scripts but has been added by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_ie = atlite.cutout.get_cutout_from_era5_data('path', ds, ['wind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
