{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe for wind verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                      # Data\n",
    "import pandas as pd                     # Data \n",
    "import geopandas as gpd                 # Data\n",
    "import xarray as xr                     # Data\n",
    "import atlite                           # Model\n",
    "import matplotlib.pyplot as plt         # Plot\n",
    "from matplotlib.lines import Line2D     # Plot\n",
    "from tqdm import tqdm                   # Visualise progression in loop\n",
    "import yaml                             # Open yaml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations of farms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file located in /Data_Final folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data_Final/EirGrid/capacity_pv_1424_eir.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_capacity \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data_Final/EirGrid/capacity_pv_1424_eir.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data_Final/EirGrid/capacity_pv_1424_eir.csv'"
     ]
    }
   ],
   "source": [
    "df_capacity = pd.read_csv('../Data_Final/EirGrid/capacity_pv_1424_eir.csv',\n",
    "                               index_col = 2,\n",
    "                               parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns to be correctly read by Atlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity = df_capacity.dropna().rename(columns={'Capacity (MW)':'capacity', 'latitude':'y', 'longitude':'x'})\n",
    "df_capacity = df_capacity[df_capacity.index < '2024'] # Make sure to remove all data before 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the connection date for the large capacities installed in 2023 whose installation date we estimated from the EirGrid data and simulations using this capacity. Namely:\n",
    "\n",
    "- First two IC installations: 2023-04-01 -> \"Rosspile\" (95 MW) and \"Gillinstown\" (95 MW)\n",
    "- Third IC installation: 2023-04-26 -> \"Gallanstown\" (119 MW)\n",
    "- Fourth IC installation: 2023-06-12 -> \"Blundelstown\" (60 MW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_connection_dates = {\n",
    "    'Rosspile': pd.to_datetime('2023-04-01'),\n",
    "    'Gillinstown': pd.to_datetime('2023-04-01'),\n",
    "    'Gallanstown': pd.to_datetime('2023-04-26'),\n",
    "    'Blundelstown': pd.to_datetime('2023-06-12')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for place, new_date in new_connection_dates.items():\n",
    "    index_tmp = df_capacity[df_capacity['Name'] == place].index\n",
    "    if not index_tmp.empty:\n",
    "        df_capacity = df_capacity.rename(index={index_tmp[0]: new_date})\n",
    "\n",
    "df_capacity.index = pd.to_datetime(df_capacity.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cutout for Ireland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weather files downloaded on Copernicus website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ERA5 files located in local folders\n",
    "ds_temperature = xr.open_dataset('../Data/ERA5/ERA5_2m_temperature_soil_temperature_level_4_hourly_2018_2023.nc')\n",
    "ds_radiation_sfc = xr.open_dataset('../Data/ERA5/ERA5_surface_net_solar_radiation_surface_solar_radiation_downwards_hourly_2018_2023.nc')\n",
    "ds_radiation_toa = xr.open_dataset('../Data/ERA5/ERA5_toa_incident_solar_radiation_total_sky_direct_solar_radiation_at_surface_hourly_2018_2023.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables need to be formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temperature = ds_temperature.reduce(np.nanmean, dim='expver',keep_attrs=True)\n",
    "ds_radiation_sfc = ds_radiation_sfc.reduce(np.nanmean, dim='expver',keep_attrs=True)\n",
    "ds_radiation_toa = ds_radiation_toa.reduce(np.nanmean, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them\n",
    "ds = xr.merge([ds_temperature, ds_radiation_sfc, ds_radiation_toa])\n",
    "ds = ds.sel(time=slice(\"2018-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the climate variables in Atlite\n",
    "\n",
    "This can only be done via the function get_cutout_from_era5_data which is not originally in the Atlite scripts but has been added by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_ie = atlite.cutout.get_cutout_from_era5_data('path', ds, ['influx', 'temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create a time dependent layout of the capacity from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dependent_capacity_distribution(cutout_ie: atlite.Cutout, df_capacity: pd.DataFrame):\n",
    "    capacity_layout = cutout_ie.data['temperature'].copy()\n",
    "    capacity_layout.name = 'Capacity'\n",
    "    capacity_layout[:,:,:] = 0.\n",
    "\n",
    "    # Iterate over all capacity installations\n",
    "    for idx, row in tqdm(df_capacity.reset_index().iterrows(), total= df_capacity.shape[0]):\n",
    "        cap = row['capacity']\n",
    "        df_capacity_i = pd.DataFrame([row])\n",
    "        layout = cutout_ie.layout_from_capacity_list(df_capacity_i, col=\"capacity\")\n",
    "\n",
    "        capacity_layout[capacity_layout['time']>=row['Connection date']] += layout\n",
    "\n",
    "    return capacity_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get atlite generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_atlite(cutout_ie: atlite.Cutout, capacity_layout, panel, orientation):\n",
    "    pv_cf = atlite.convert.convert_pv(cutout_ie.data, panel=atlite.convert.get_solarpanelconfig(panel), orientation=atlite.convert.get_orientation(orientation), tracking=None)\n",
    "    if isinstance(capacity_layout, xr.DataArray):\n",
    "        return pv_cf.weighted(capacity_layout).mean(('x','y'))\n",
    "    elif isinstance(capacity_layout, pd.DataFrame):\n",
    "        return pv_cf.weighted(get_time_dependent_capacity_distribution(cutout_ie, capacity_layout).mean(('x','y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity Factor\n",
    "\n",
    "Now we calculate the wind capacity factor series for both the smoothed and non-smoothed curves. We will compare the two to EirGrid before comparing the different methods to visualise the effective difference this makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 16.66it/s]\n"
     ]
    }
   ],
   "source": [
    "full_time_layout = get_time_dependent_capacity_distribution(cutout_ie = cutout_ie, df_capacity = df_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_atlite = get_cf_series_atlite(cutout_ie=cutout_ie, capacity_layout=full_time_layout, panel='KANENA', orientation='latitude_optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E Gridded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CF data from C3S-Energy from 2017 to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_gridded = xr.open_dataarray('../Data/C3S-E/c3se_solar_capacityfactor_20180101_20231231_gridded_ireland.nc')\n",
    "da_gridded = da_gridded.sel(time=slice(\"2018-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_c3se_gridded(da_gridded: xr.DataArray, df_capacity_solar: pd.DataFrame, only_cf: bool = True):\n",
    "    lats = da_gridded['latitude'].values\n",
    "    lons = da_gridded['longitude'].values\n",
    "\n",
    "    summed_time_series = np.zeros(da_gridded['time'].shape)\n",
    "    total_capacity_time_series  = np.zeros(da_gridded['time'].shape)\n",
    "\n",
    "    # Iterate over all capacity installations\n",
    "    for idx, row in df_capacity_solar.reset_index().iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        cap = row['capacity']\n",
    "\n",
    "    # Find the nearest lat/lon point\n",
    "        dif_min_lon = np.argmin(abs(lons-x))\n",
    "        dif_min_lat = np.argmin(abs(lats-y))\n",
    "\n",
    "        time_series = da_gridded[:, dif_min_lat, dif_min_lon]\n",
    "\n",
    "        capacity_time_series = time_series.copy()\n",
    "        capacity_time_series[:] = cap\n",
    "\n",
    "        time_series[time_series['time']<row['Connection date']] = 0.\n",
    "        capacity_time_series[capacity_time_series['time']<row['Connection date']] = 0.\n",
    "\n",
    "    # Add the mean CF time series to the total multiplied by the capacity (weight)\n",
    "        summed_time_series += cap*time_series\n",
    "        total_capacity_time_series += capacity_time_series\n",
    "\n",
    "    # Divide the total time series by the total IC to go back to CF\n",
    "    cf_time_series = summed_time_series/total_capacity_time_series\n",
    "    if only_cf:\n",
    "        return cf_time_series\n",
    "    return cf_time_series, summed_time_series, total_capacity_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_gridded = get_cf_series_c3se_gridded(da_gridded=da_gridded, df_capacity_solar=df_capacity, only_cf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E National"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = pd.read_csv('../Data/C3S-E/c3se_solar_capacityfactor_national.csv',\n",
    "                         skiprows = 52,\n",
    "                         usecols = [0,18], # Retrieve IE data\n",
    "                         index_col = 0,\n",
    "                         parse_dates = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E Subnational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('../Data/C3S-E/c3se_solar_capacityfactor_subnational.csv',\n",
    "                     skiprows = 52,\n",
    "                     usecols = [0,350], # Data for NI\n",
    "                     index_col = 0,\n",
    "                     parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Time of verification (2017 - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat[(\"2018\" <= df_nat.index) & (df_nat.index < \"2024\")]\n",
    "df_sub = df_sub[(\"2018\" <= df_sub.index) & (df_sub.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 37.12it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.42it/s]\n"
     ]
    }
   ],
   "source": [
    "capacity_series_ie = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='ROI'])\n",
    "capacity_series_ni = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='NI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the results into one time series for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_series_ie = capacity_series_ie.sum(dim=['x','y'])\n",
    "capacity_series_ni = capacity_series_ni.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "The C3S-E National data is missing data for the 31st of December of 2019. We add it here and make it NaN in order to facilitate further treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat.loc[pd.to_datetime('2019-12-31T22:00'), 'IE'] = np.nan\n",
    "df_nat.loc[pd.to_datetime('2019-12-31T23:00'), 'IE'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T22:00'), 'UKN0'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T23:00'), 'UKN0'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resort the data to avoid future issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat.sort_index()\n",
    "df_sub = df_sub.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we average the two times series with capacities as weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_national = (df_nat['IE']*capacity_series_ie + df_sub['UKN0']*capacity_series_ni) / (capacity_series_ie + capacity_series_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eirgrid_qtr = pd.read_csv('../Data_Final/EirGrid/generation_pv_1823_eir.csv',\n",
    "                          index_col = 0,\n",
    "                          parse_dates = True)\n",
    "eirgrid_qtr = eirgrid_qtr[(\"2017\" <= eirgrid_qtr.index) & (eirgrid_qtr.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_eirgrid = eirgrid_qtr['Availability'].resample('1h').mean() / full_time_layout.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data as csv file to be used again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time':cf_eirgrid.index, 'EirGrid':cf_eirgrid.values, 'Atlite': cf_atlite.values, 'C3S National': cf_c3se_national.values, 'C3S Gridded': cf_c3se_gridded.values})\n",
    "df = df.set_index('time')\n",
    "df.to_csv('../Data_Final/Verification/verification_cf_pv_1823.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
