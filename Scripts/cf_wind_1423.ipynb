{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe for wind verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                      # Data\n",
    "import pandas as pd                     # Data \n",
    "import geopandas as gpd                 # Data\n",
    "import xarray as xr                     # Data\n",
    "import atlite                           # Model\n",
    "import matplotlib.pyplot as plt         # Plot\n",
    "from matplotlib.lines import Line2D     # Plot\n",
    "from tqdm import tqdm                   # Visualise progression in loop\n",
    "import yaml                             # Open yaml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations of farms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file located in /Data_Final folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity = pd.read_csv('../Data_Final/EirGrid/capacity_wind_9224_eir.csv',\n",
    "                               index_col = 2,\n",
    "                               parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns to be correctly read by Atlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity = df_capacity.dropna().rename(columns={'Capacity (MW)':'capacity', 'Latitude':'y', 'Longitude':'x'})\n",
    "df_capacity = df_capacity[df_capacity.index < '2024'] # Make sure to remove all data before 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cutout for Ireland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weather files downloaded on Copernicus website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/anaconda3/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.24.2\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_uv100_to2018 = xr.open_dataset('../Data/ERA5/ERA5_100m_u_v_hourly_2009_2018.nc')\n",
    "ds_uv100_2019_2023 = xr.open_dataset('../Data/ERA5/ERA5_100m_u_v_hourly_2019_2023.nc')\n",
    "ds_roughness_2018_2023 = xr.open_dataset('../Data/ERA5/ERA5_forecast_surface_roughness_geopotential_hourly_2018_2023.nc')\n",
    "ds_roughness_to2017 = xr.open_dataset('../Data/ERA5/ERA5_forecast_surface_roughness_geopotential_hourly_2012_2017.nc')\n",
    "ds_uv100_to2018 = ds_uv100_to2018.sel(time=slice(\"2014-01-01\", \"2018-12-31\"))\n",
    "ds_roughness_to2018 = ds_roughness_to2017.sel(time=slice(\"2014-01-01\", \"2017-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables need to be formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv100_2019_2023 = ds_uv100_2019_2023.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_roughness_2018_2023 = ds_roughness_2018_2023.reduce(np.nansum, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset does not contain the dimensions: ['expver']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds_uv100_2019_2023 \u001b[38;5;241m=\u001b[39m ds_uv100_2019_2023\u001b[38;5;241m.\u001b[39mreduce(np\u001b[38;5;241m.\u001b[39mnansum, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpver\u001b[39m\u001b[38;5;124m'\u001b[39m,keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m ds_roughness_2018_2023 \u001b[38;5;241m=\u001b[39m ds_roughness_2018_2023\u001b[38;5;241m.\u001b[39mreduce(np\u001b[38;5;241m.\u001b[39mnansum, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpver\u001b[39m\u001b[38;5;124m'\u001b[39m,keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/dataset.py:5941\u001b[0m, in \u001b[0;36mDataset.reduce\u001b[0;34m(self, func, dim, keep_attrs, keepdims, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   5939\u001b[0m missing_dimensions \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dims \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims]\n\u001b[1;32m   5940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dimensions:\n\u001b[0;32m-> 5941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5942\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset does not contain the dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_dimensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5943\u001b[0m     )\n\u001b[1;32m   5945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5946\u001b[0m     keep_attrs \u001b[38;5;241m=\u001b[39m _get_keep_attrs(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset does not contain the dimensions: ['expver']"
     ]
    }
   ],
   "source": [
    "ds_uv100_2019_2023 = ds_uv100_2019_2023.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_roughness_2018_2023 = ds_roughness_2018_2023.reduce(np.nansum, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_uv100 = xr.concat([ds_uv100_to2018.rename({'lat':'latitude', 'lon':'longitude'}), ds_uv100_2019_2023], dim='time')\n",
    "ds_roughness = xr.concat([ds_roughness_to2017, ds_roughness_2018_2023], dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([ds_uv100, ds_roughness])\n",
    "ds = ds.sel(time=slice(\"2014-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the climate variables in Atlite\n",
    "\n",
    "This can only be done via the function get_cutout_from_era5_data which is not originally in the Atlite scripts but has been added by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_ie = atlite.cutout.get_cutout_from_era5_data('path', ds, ['wind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create a time dependent layout of the capacity from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dependent_capacity_distribution(cutout_ie: atlite.Cutout, df_capacity: pd.DataFrame):\n",
    "    capacity_layout = cutout_ie.data['roughness'].copy()\n",
    "    capacity_layout.name = 'Capacity'\n",
    "    capacity_layout[:,:,:] = 0.\n",
    "\n",
    "    #Â Iterate over all capacity installations\n",
    "    for idx, row in tqdm(df_capacity.reset_index().iterrows(), total= df_capacity.shape[0]):\n",
    "        cap = row['capacity'] # Capacity values\n",
    "        df_capacity_i = pd.DataFrame([row])\n",
    "        layout = cutout_ie.layout_from_capacity_list(df_capacity_i, col=\"capacity\")\n",
    "\n",
    "        capacity_layout[capacity_layout['time'] >= row['Connection date']] += layout\n",
    "\n",
    "    return capacity_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get atlite generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_atlite(cutout_ie: atlite.Cutout, capacity_layout, power_curve):\n",
    "    if isinstance(power_curve, dict):\n",
    "        # Dict contains wind_speed, power, power_max, hub_height\n",
    "        wind_cf = atlite.convert.convert_wind(cutout_ie.data, power_curve)\n",
    "    elif isinstance(power_curve, str):\n",
    "        # Str name of turbine which atlite knows\n",
    "        wind_cf = atlite.convert.convert_wind(cutout_ie.data, atlite.resource.get_windturbineconfig(power_curve))\n",
    "\n",
    "    if isinstance(capacity_layout, xr.DataArray):\n",
    "        # What supposed to happen\n",
    "        return wind_cf.weighted(capacity_layout).mean(('x','y'))\n",
    "    elif isinstance(capacity_layout, pd.DataFrame):\n",
    "        # Take this path if layout is not processed by us\n",
    "        return wind_cf.weighted(get_time_dependent_capacity_distribution(cutout_ie, capacity_layout).mean(('x','y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turbines\n",
    "\n",
    "On an analysis of multiple turbines and their smoothing, we identify the Enercon.E112.4500 with 0.30w from renewables.ninja as the turbine with the best representation of EirGrid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Enercon Enercon.E112.4500 power curve and the smoothed version as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turbines_ninja_nosmoothing = pd.read_csv('../Data/renewables_ninja/Wind Turbine Power Curves ~ 5 (0.01ms with 0.00 w smoother).csv')\n",
    "turbine_ninja_nosmoothing = {'hub_height':100, 'P':1., 'V':df_turbines_ninja_nosmoothing['speed'].values, 'POW':df_turbines_ninja_nosmoothing['Enercon.E112.4500'].values}\n",
    "\n",
    "df_turbines_ninja_030smoothing = pd.read_csv('../Data/renewables_ninja/Wind Turbine Power Curves ~ 5 (0.01ms with 0.30 w smoother).csv')\n",
    "turbine_ninja_030smoothing = {'hub_height':100, 'P':1., 'V':df_turbines_ninja_030smoothing['data$speed'].values, 'POW':df_turbines_ninja_030smoothing['Enercon.E112.4500'].values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity Factor\n",
    "\n",
    "Now we calculate the wind capacity factor series for both the smoothed and non-smoothed curves. We will compare the two to EirGrid before comparing the different methods to visualise the effective difference this makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 381/381 [01:00<00:00,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "full_time_layout = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_atlite = get_cf_series_atlite(cutout_ie=cutout_ie, capacity_layout=full_time_layout, power_curve=turbine_ninja_030smoothing)\n",
    "cf_atlite_nosmooth = get_cf_series_atlite(cutout_ie=cutout_ie, capacity_layout=full_time_layout, power_curve=turbine_ninja_nosmoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E Gridded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CF data from C3S-Energy from 2014 to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_gridded = xr.open_dataarray('../Data/C3S-E/c3se_onshorewind_capacityfactor_20140101_20231231_gridded_ireland.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_c3se_gridded(da_gridded: xr.DataArray, df_capacity: pd.DataFrame, only_cf: bool = True):\n",
    "    lats = da_gridded['latitude'].values\n",
    "    lons = da_gridded['longitude'].values\n",
    "\n",
    "    error_farms_idx = []\n",
    "\n",
    "    summed_time_series = np.zeros(da_gridded['time'].shape)\n",
    "    total_capacity_time_series  = np.zeros(da_gridded['time'].shape)\n",
    "\n",
    "    #Â Iterate over all capacity installations\n",
    "    for idx, row in df_capacity.reset_index().iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        cap = row['capacity']\n",
    "\n",
    "    #Â Find the nearest lat/lon point\n",
    "        dif_min_lon = np.argmin(abs(lons-x))\n",
    "        dif_min_lat = np.argmin(abs(lats-y))\n",
    "\n",
    "        time_series = da_gridded[:, dif_min_lat, dif_min_lon]\n",
    "\n",
    "        pairs_list = [[0,0], [0,1], [1,0], [1,1], [2,0], [0,2], [2,1], [1,2]]\n",
    "        if np.isnan(time_series).sum() > 2:\n",
    "            for pair in pairs_list:\n",
    "                dif_min_lon = np.argsort(abs(lons-x))[pair[0]]\n",
    "                dif_min_lat = np.argsort(abs(lats-y))[pair[1]]\n",
    "                time_series = da_gridded[:, dif_min_lat, dif_min_lon]\n",
    "                if np.isnan(time_series).sum() <= 2:\n",
    "                    break\n",
    "\n",
    "        capacity_time_series = time_series.copy()\n",
    "        capacity_time_series[:] = cap\n",
    "\n",
    "        time_series[time_series['time']<row['Connection date']] = 0.\n",
    "        capacity_time_series[capacity_time_series['time']<row['Connection date']] = 0.\n",
    "\n",
    "    #Â Add the mean CF time series to the total multiplied by the capacity (weight)\n",
    "        if np.isnan(time_series).sum() <= 2:\n",
    "            summed_time_series += cap*time_series\n",
    "            total_capacity_time_series += capacity_time_series\n",
    "        else:\n",
    "            print(idx, row)\n",
    "\n",
    "    #Â Divide the total time series by the total IC to go back to CF\n",
    "    cf_time_series = summed_time_series/total_capacity_time_series\n",
    "    if only_cf:\n",
    "        return cf_time_series\n",
    "    return cf_time_series, summed_time_series, total_capacity_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_gridded = get_cf_series_c3se_gridded(da_gridded=da_gridded, df_capacity=df_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For C3S-Energy the wind turbine power curve is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import safe_load\n",
    "path_turbines_vestas = '../Data/power_curve_Vestas_V136_3450_c3se.yaml'\n",
    "with open(path_turbines_vestas, 'r') as f:\n",
    "    df_turbines_vestas = pd.json_normalize(safe_load(f))\n",
    "    turbine_vestas = {'hub_height':100, 'P':1, 'V':np.array(df_turbines_vestas['V'].values[0]), 'POW':np.array(df_turbines_vestas['NPOW'].values[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_atlite_vestas = get_cf_series_atlite(cutout_ie=cutout_ie, capacity_layout=full_time_layout, power_curve=turbine_vestas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E National"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = pd.read_csv('../Data/C3S-E/c3se_onshorewind_capacityfactor_national.csv',\n",
    "                         skiprows = 52,\n",
    "                         usecols = [0,18], # Retrieve IE data\n",
    "                         index_col = 0,\n",
    "                         parse_dates = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Time of verification (2014 - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat[(\"2014\" <= df_nat.index) & (df_nat.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E Subnational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('../Data/C3S-E/c3se_onshorewind_capacityfactor_subnational.csv',\n",
    "                     skiprows = 52,\n",
    "                     usecols = [0,350], # Data for NI\n",
    "                     index_col = 0,\n",
    "                     parse_dates = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Time of verification (2014 - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub[(\"2014\" <= df_sub.index) & (df_sub.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 315/315 [00:46<00:00,  6.78it/s]\n",
      "100%|ââââââââââ| 66/66 [00:09<00:00,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "capacity_series_ie = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='ROI'])\n",
    "capacity_series_ni = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='NI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the results into one time series for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_series_ie = capacity_series_ie.sum(dim=['x','y'])\n",
    "capacity_series_ni = capacity_series_ni.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "The C3S-E National data is missing data for the 31st of December of 2019. We add it here and make it NaN in order to facilitate further treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat.loc[pd.to_datetime('2019-12-31T22:00'), 'IE'] = np.nan\n",
    "df_nat.loc[pd.to_datetime('2019-12-31T23:00'), 'IE'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T22:00'), 'UKN0'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T23:00'), 'UKN0'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resort the data to avoid future issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat.sort_index()\n",
    "df_sub = df_sub.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we average the two times series with capacities as weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_national = (df_nat['IE']*capacity_series_ie + df_sub['UKN0']*capacity_series_ni) / (capacity_series_ie + capacity_series_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eirgrid_qtr = pd.read_csv('../Data_Final/EirGrid/eirgrid_qtr_15min_wind_generation_availability_20140101_20231231.csv',\n",
    "                          index_col = 0,\n",
    "                          parse_dates = True)\n",
    "eirgrid_qtr = eirgrid_qtr[(\"2014\" <= eirgrid_qtr.index) & (eirgrid_qtr.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_eirgrid = eirgrid_qtr['Availability'].resample('1h').mean() / full_time_layout.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data as csv file to be used again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time':cf_eirgrid.index,\n",
    "                    'EirGrid':cf_eirgrid.values,\n",
    "                    'Atlite': cf_atlite.values,\n",
    "                    'C3S Gridded': cf_c3se_gridded.values,\n",
    "                    'C3S National': cf_c3se_national.values}\n",
    "                )\n",
    "df = df.set_index('time')\n",
    "df.to_csv('../Data/verification_cf_wind_1423.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
