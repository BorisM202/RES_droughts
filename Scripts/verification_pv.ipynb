{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe for wind verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                      # Data\n",
    "import pandas as pd                     # Data \n",
    "import geopandas as gpd                 # Data\n",
    "import xarray as xr                     # Data\n",
    "import atlite                           # Model\n",
    "import matplotlib.pyplot as plt         # Plot\n",
    "from matplotlib.lines import Line2D     # Plot\n",
    "from tqdm import tqdm                   # Visualise progression in loop\n",
    "import yaml                             # Open yaml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations of farms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file located in /Data_Final folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity = pd.read_csv('../Data_Final/EirGrid/capacity_pv_1424_eir.csv',\n",
    "                               index_col = 2,\n",
    "                               parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns to be correctly read by Atlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capacity = df_capacity.dropna().rename(columns={'Capacity (MW)':'capacity', 'latitude':'y', 'longitude':'x'})\n",
    "df_capacity = df_capacity[df_capacity.index < '2024'] # Make sure to remove all data before 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the connection date for the large capacities installed in 2023 whose installation date we estimated from the EirGrid data and simulations using this capacity. Namely:\n",
    "\n",
    "- First two IC installations: 2023-04-01 -> \"Rosspile\" (95 MW) and \"Gillinstown\" (95 MW)\n",
    "- Third IC installation: 2023-04-26 -> \"Gallanstown\" (119 MW)\n",
    "- Fourth IC installation: 2023-06-12 -> \"Blundelstown\" (60 MW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_connection_dates = {\n",
    "    'Rosspile': pd.to_datetime('2023-04-01'),\n",
    "    'Gillinstown': pd.to_datetime('2023-04-01'),\n",
    "    'Gallanstown': pd.to_datetime('2023-04-26'),\n",
    "    'Blundelstown': pd.to_datetime('2023-06-12')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for place, new_date in new_connection_dates.items():\n",
    "    index_tmp = df_capacity[df_capacity['Name'] == place].index\n",
    "    if not index_tmp.empty:\n",
    "        df_capacity = df_capacity.rename(index={index_tmp[0]: new_date})\n",
    "\n",
    "df_capacity.index = pd.to_datetime(df_capacity.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cutout for Ireland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weather files downloaded on Copernicus website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ERA5 files located in local folders\n",
    "ds_temperature = xr.open_dataset('../Data/ERA5/ERA5_2m_temperature_soil_temperature_level_4_hourly_2018_2023.nc')\n",
    "ds_radiation_sfc = xr.open_dataset('../Data/ERA5/ERA5_surface_net_solar_radiation_surface_solar_radiation_downwards_hourly_2018_2023.nc')\n",
    "ds_radiation_toa = xr.open_dataset('../Data/ERA5/ERA5_toa_incident_solar_radiation_total_sky_direct_solar_radiation_at_surface_hourly_2018_2023.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables need to be formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_temperature = ds_temperature.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_radiation_sfc = ds_radiation_sfc.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "ds_radiation_toa = ds_radiation_toa.reduce(np.nansum, dim='expver',keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them\n",
    "ds = xr.merge([ds_temperature, ds_radiation_sfc, ds_radiation_toa])\n",
    "ds = ds.sel(time=slice(\"2018-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the climate variables in Atlite\n",
    "\n",
    "This can only be done via the function get_cutout_from_era5_data which is not originally in the Atlite scripts but has been added by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_ie = atlite.cutout.get_cutout_from_era5_data('path', ds, ['influx', 'temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create a time dependent layout of the capacity from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dependent_capacity_distribution(cutout_ie: atlite.Cutout, df_capacity: pd.DataFrame):\n",
    "    capacity_layout = cutout_ie.data['temperature'].copy()\n",
    "    capacity_layout.name = 'Capacity'\n",
    "    capacity_layout[:,:,:] = 0.\n",
    "\n",
    "    # Iterate over all capacity installations\n",
    "    for idx, row in tqdm(df_capacity.reset_index().iterrows(), total= df_capacity.shape[0]):\n",
    "        cap = row['capacity']\n",
    "        df_capacity_i = pd.DataFrame([row])\n",
    "        layout = cutout_ie.layout_from_capacity_list(df_capacity_i, col=\"capacity\")\n",
    "\n",
    "        capacity_layout[capacity_layout['time']>=row['Connection date']] += layout\n",
    "\n",
    "    return capacity_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get atlite generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_atlite(cutout_ie: atlite.Cutout, capacity_layout, panel, orientation):\n",
    "    pv_cf = atlite.convert.convert_pv(cutout_ie.data, panel=atlite.convert.get_solarpanelconfig(panel), orientation=atlite.convert.get_orientation(orientation), tracking=None)\n",
    "    if isinstance(capacity_layout, xr.DataArray):\n",
    "        return pv_cf.weighted(capacity_layout).mean(('x','y'))\n",
    "    elif isinstance(capacity_layout, pd.DataFrame):\n",
    "        return pv_cf.weighted(get_time_dependent_capacity_distribution(cutout_ie, capacity_layout).mean(('x','y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity Factor\n",
    "\n",
    "Now we calculate the wind capacity factor series for both the smoothed and non-smoothed curves. We will compare the two to EirGrid before comparing the different methods to visualise the effective difference this makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 16.66it/s]\n"
     ]
    }
   ],
   "source": [
    "full_time_layout = get_time_dependent_capacity_distribution(cutout_ie = cutout_ie, df_capacity = df_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_atlite = get_cf_series_atlite(cutout_ie=cutout_ie, capacity_layout=full_time_layout, panel='KANENA', orientation='latitude_optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E Gridded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CF data from C3S-Energy from 2017 to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_gridded = xr.open_dataarray('../Data/C3S-E/c3se_solar_capacityfactor_20180101_20231231_gridded_ireland.nc')\n",
    "da_gridded = da_gridded.sel(time=slice(\"2018-01-01\", \"2023-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_series_c3se_gridded(da_gridded: xr.DataArray, df_capacity_solar: pd.DataFrame, only_cf: bool = True):\n",
    "    lats = da_gridded['latitude'].values\n",
    "    lons = da_gridded['longitude'].values\n",
    "\n",
    "    summed_time_series = np.zeros(da_gridded['time'].shape)\n",
    "    total_capacity_time_series  = np.zeros(da_gridded['time'].shape)\n",
    "\n",
    "    # Iterate over all capacity installations\n",
    "    for idx, row in df_capacity_solar.reset_index().iterrows():\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        cap = row['capacity']\n",
    "\n",
    "    # Find the nearest lat/lon point\n",
    "        dif_min_lon = np.argmin(abs(lons-x))\n",
    "        dif_min_lat = np.argmin(abs(lats-y))\n",
    "\n",
    "        time_series = da_gridded[:, dif_min_lat, dif_min_lon]\n",
    "\n",
    "        capacity_time_series = time_series.copy()\n",
    "        capacity_time_series[:] = cap\n",
    "\n",
    "        time_series[time_series['time']<row['Connection date']] = 0.\n",
    "        capacity_time_series[capacity_time_series['time']<row['Connection date']] = 0.\n",
    "\n",
    "    # Add the mean CF time series to the total multiplied by the capacity (weight)\n",
    "        summed_time_series += cap*time_series\n",
    "        total_capacity_time_series += capacity_time_series\n",
    "\n",
    "    # Divide the total time series by the total IC to go back to CF\n",
    "    cf_time_series = summed_time_series/total_capacity_time_series\n",
    "    if only_cf:\n",
    "        return cf_time_series\n",
    "    return cf_time_series, summed_time_series, total_capacity_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_gridded = get_cf_series_c3se_gridded(da_gridded=da_gridded, df_capacity_solar=df_capacity, only_cf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S-E National"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = pd.read_csv('../Data/C3S-E/c3se_solar_capacityfactor_national.csv',\n",
    "                         skiprows = 52,\n",
    "                         usecols = [0,18], # Retrieve IE data\n",
    "                         index_col = 0,\n",
    "                         parse_dates = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file containing Capacity Factor from C3S-E Subnational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('../Data/C3S-E/c3se_solar_capacityfactor_subnational.csv',\n",
    "                     skiprows = 52,\n",
    "                     usecols = [0,350], # Data for NI\n",
    "                     index_col = 0,\n",
    "                     parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Time of verification (2017 - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat[(\"2018\" <= df_nat.index) & (df_nat.index < \"2024\")]\n",
    "df_sub = df_sub[(\"2018\" <= df_sub.index) & (df_sub.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 37.12it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.42it/s]\n"
     ]
    }
   ],
   "source": [
    "capacity_series_ie = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='ROI'])\n",
    "capacity_series_ni = get_time_dependent_capacity_distribution(cutout_ie=cutout_ie, df_capacity=df_capacity[df_capacity['ROI/NI']=='NI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the results into one time series for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_series_ie = capacity_series_ie.sum(dim=['x','y'])\n",
    "capacity_series_ni = capacity_series_ni.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "The C3S-E National data is missing data for the 31st of December of 2019. We add it here and make it NaN in order to facilitate further treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat.loc[pd.to_datetime('2019-12-31T22:00'), 'IE'] = np.nan\n",
    "df_nat.loc[pd.to_datetime('2019-12-31T23:00'), 'IE'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T22:00'), 'UKN0'] = np.nan\n",
    "df_sub.loc[pd.to_datetime('2019-12-31T23:00'), 'UKN0'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resort the data to avoid future issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nat = df_nat.sort_index()\n",
    "df_sub = df_sub.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we average the two times series with capacities as weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52584, 1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52584,)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capacity_series_ie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_c3se_national = (df_nat['IE']*capacity_series_ie + df_sub['UKN0']*capacity_series_ni) / (capacity_series_ie + capacity_series_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EirGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "eirgrid_qtr = pd.read_csv('../Data_Final/EirGrid/generation_pv_1823_eir.csv',\n",
    "                          index_col = 0,\n",
    "                          parse_dates = True)\n",
    "eirgrid_qtr = eirgrid_qtr[(\"2017\" <= eirgrid_qtr.index) & (eirgrid_qtr.index < \"2024\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_eirgrid = eirgrid_qtr['Availability'].resample('1h').mean() / full_time_layout.sum(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data as csv file to be used again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time':cf_eirgrid.index, 'EirGrid':cf_eirgrid.values, 'Atlite': cf_atlite.values, 'C3S National': cf_c3se_national.values, 'C3S Gridded': cf_c3se_gridded.values})\n",
    "df = df.set_index('time')\n",
    "df.to_csv('../Data_Final/Verification/verification_cf_pv_1823.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
